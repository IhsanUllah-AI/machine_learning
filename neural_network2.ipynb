{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import keras as k\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from keras import losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import  load_digits\n",
    "digit=load_digits()\n",
    "x=digit.data\n",
    "y=digit.target\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "x=scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "softmax is used for multi class classification \n",
    "cal z1....z10 then a1.....a10\n",
    "z is simple linaer \n",
    "a1=exp(z1)/exp(z1)+exp(z2).....exp(z10) same a2 upto a10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1705 - loss: 2.3619\n",
      "Epoch 2/5\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5091 - loss: 1.8058\n",
      "Epoch 3/5\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6912 - loss: 1.3286\n",
      "Epoch 4/5\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7627 - loss: 0.9748\n",
      "Epoch 5/5\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8098 - loss: 0.7376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1cabad8b010>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential(\n",
    "    [\n",
    "       layers.Dense(units=25,activation='relu'),\n",
    "       layers.Dense(units=15,activation='relu'),\n",
    "       layers.Dense(units=10,activation='softmax')\n",
    "    ]\n",
    ")\n",
    "model.compile(loss=losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])#this loss func is used for multiclass classifcation\n",
    "model.fit(x_train,y_train,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "used relu in hidden layer is natural best choise \n",
    "for binary classifaction used sigmoid \n",
    "for mutli // used softmax  also units has multiple\n",
    "for reg which has positiev and negatiove both used linear \n",
    "for reg has only positive value like house price prediction used relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.6583780e-15, 9.9755919e-01, 3.7366314e-09, 3.3060441e-08,\n",
       "        2.0952661e-04, 5.8442140e-13, 1.4758705e-14, 5.9174909e-04,\n",
       "        1.6395844e-03, 1.4796489e-16]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=digit.data[2].reshape(1,-1)\n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "softmax used  find (a) vector value which is directly used in loss function which less accuracte numerical\n",
    "a=exp(zj)/sum fro k=1 upto n exp(zj) \n",
    "loss=-ylog a1 -(1-y)log a2\n",
    "use intermediat of a mean use 1/1+exp(z) instead of (a) vactor\n",
    "for this used (linear) instead of softmax or sigmoid to find value of z and pass from_logit parameter to compile function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1819 - loss: 2.2808\n",
      "Epoch 2/5\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4596 - loss: 1.6511\n",
      "Epoch 3/5\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5703 - loss: 1.3050\n",
      "Epoch 4/5\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7199 - loss: 0.9323\n",
      "Epoch 5/5\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8113 - loss: 0.6838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1cac02b0d10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md=Sequential([\n",
    "       layers.Dense(units=25,activation='relu'),\n",
    "       layers.Dense(units=15,activation='relu'),\n",
    "       layers.Dense(units=10,activation='linear')\n",
    "])\n",
    "md.compile(loss=losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "md.fit(x_train,y_train,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "give us numerical more accurate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -9.3858   ,  35.53699  ,  12.891483 ,  -2.9155002, -12.218384 ,\n",
       "        -11.559463 , -10.592284 , -25.19093  ,  26.210361 , -19.572111 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.predict(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
